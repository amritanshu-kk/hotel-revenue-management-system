{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "presidential-crisis",
   "metadata": {},
   "source": [
    "# Welcome to the Revenue Management Simulation!\n",
    "\n",
    "First, make sure you've read by blog post about the project, so you have an understanding of the steps. Then, follow along to reproduce the project on your local computer.\n",
    "\n",
    "For more information about what's happening behind the scenes, take a look at the `.py` scripts in `code` folder.\n",
    "\n",
    "As-of-date (abbreviated 'AOD') is 2017-08-01. We will be trying to predict cancellations and demand for each day in August 2017.\n",
    "\n",
    "### Let's start with some imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intelligent-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from dbds import generate_hotel_dfs\n",
    "from save_sims import save_historical_OTB\n",
    "from agg import prep_demand_features\n",
    "from demand import model_demand\n",
    "\n",
    "pd.options.display.max_rows = 150\n",
    "pd.options.display.max_columns = 250\n",
    "pd.options.display.max_colwidth = None\n",
    "\n",
    "aod = '2017-08-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-registration",
   "metadata": {},
   "source": [
    "### Let's also make sure we have a `code/pickle` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sublime-raising",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: pickle: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir pickle # create an empty pickle folder if it doesn't exist (will not work on Windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-offering",
   "metadata": {},
   "source": [
    "### Now, let's get our reservations ready for modeling, and calculate actual hotel statistics.\n",
    "\n",
    "Time to execute: < 30 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "manual-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_res, h1_dbd = generate_hotel_dfs(\"../data/H1.csv\", capacity=187)\n",
    "h2_res, h2_dbd = generate_hotel_dfs(\"../data/H2.csv\", capacity=226)\n",
    "\n",
    "h1_res.to_pickle(\"pickle/h1_res.pick\")\n",
    "h1_dbd.to_pickle(\"pickle/h1_dbd.pick\")\n",
    "h2_res.to_pickle(\"pickle/h2_res.pick\")\n",
    "h2_dbd.to_pickle(\"pickle/h2_dbd.pick\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-montreal",
   "metadata": {},
   "source": [
    "### Now let's calculate current OTB (on the books) statistics, as of every date from 2016-07-01 to 2017-08-30.\n",
    "\n",
    "This is necessary to get demand features for each future arrival date, namely:\n",
    "* On the books same-time-last year\n",
    "* Recent booking trends (T-30, T-15, T-5)\n",
    "* Pace\n",
    "\n",
    "**Running the below (commented) code will take several hours the first time.** It trains and runs the predictive cancellation model (along with many other calculations), and saves a pickled file for each day, for each hotel. For information about exactly what's happening with each iteration, take a look at `sim.py`. \n",
    "\n",
    "In the real-world, this wouldn't be necessary, as we could simply save one file per day and access it whenever we need to. But given the situation, it's a necessary step.\n",
    "\n",
    "**To avoid this, I've saved the aggregated output into one csv for each hotel.** These files are `../data/h1_stats.csv` and `../data/h2_stats.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "verbal-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_historical_otb(h1_dbd, h1_res, h2_dbd, h2_res) # this one takes several hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "primary-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these process the resulting files from save_historical_otb\n",
    "\n",
    "# h1_sim = prep_demand_features(1)\n",
    "# h2_sim = prep_demand_features(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "collected-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the faster route (use the CSVs in the repo):\n",
    "date_cols = ['StayDate',\n",
    " 'STLY_StayDate',\n",
    " 'AsOfDate',\n",
    " 'STLY_AsOfDate',\n",
    " 'AsOfDate_STLY',\n",
    " 'StayDate_STLY']\n",
    "\n",
    "h1_sim = pd.read_csv(\"../data/h1_stats.csv\", parse_dates=date_cols, infer_datetime_format=True)\n",
    "h1_sim.drop(columns=[\"STLY_Stay_Date\", \"STLY_AsOfDate\", \"Unnamed: 0\"], errors='ignore', inplace=True) # remove dup. columns\n",
    "h1_sim.reset_index(inplace=True)\n",
    "\n",
    "h2_sim = pd.read_csv(\"../data/h2_stats.csv\", parse_dates=date_cols, infer_datetime_format=True)\n",
    "h2_sim.drop(columns=[\"STLY_Stay_Date\", \"STLY_AsOfDate\", \"Unnamed: 0\"], errors='ignore', inplace=True) # remove dup. columns\n",
    "h2_sim.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-retirement",
   "metadata": {},
   "source": [
    "### Now we can predict demand for each day in August, using the below two cells.\n",
    "\n",
    "Note: Ignore the pricing information. I attempted to use price as a feature to predict demand, but it wasn't working. The reason is because I don't have historical selling price data, nor competitor pricing data, so there was no way to teach the model to recognize that increasing price reduces demand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "destroyed-evolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model to predict remaining transient demand...\n",
      "Model ready.\n",
      "\n",
      "R² score on test set (stay dates Aug 1 - Aug 31, 2017):                        0.743\n",
      "MAE (Mean Absolute Error) score on test set (stay dates Aug 1 - Aug 31, 2017): 2.31\n",
      "MSE (Mean Squared Error) score on test set (stay dates Aug 1 - Aug 31, 2017):  8.111\n",
      "\n",
      "Calculating optimal selling prices...\n",
      "\n",
      "Average recommended price change...                                            44.93\n",
      "Estimated RN (Roomnight) growth after implementing price recommendations...    0.0\n",
      "Estimated revenue growth after implementing price recommendations...           7086.34\n",
      "Simulation ready.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h1_demand = model_demand(1, h1_sim, aod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ancient-dispatch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model to predict remaining transient demand...\n",
      "Model ready.\n",
      "\n",
      "R² score on test set (stay dates Aug 1 - Aug 31, 2017):                        0.748\n",
      "MAE (Mean Absolute Error) score on test set (stay dates Aug 1 - Aug 31, 2017): 2.288\n",
      "MSE (Mean Squared Error) score on test set (stay dates Aug 1 - Aug 31, 2017):  7.979\n",
      "\n",
      "Calculating optimal selling prices...\n",
      "\n",
      "Average recommended price change...                                            43.23\n",
      "Estimated RN (Roomnight) growth after implementing price recommendations...    -0.0\n",
      "Estimated revenue growth after implementing price recommendations...           7077.21\n",
      "Simulation ready.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h2_demand = model_demand(2, h1_sim, aod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-residence",
   "metadata": {},
   "source": [
    "## That's it! Now you're ready to look through all of these dataFrames we've created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-feeling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
